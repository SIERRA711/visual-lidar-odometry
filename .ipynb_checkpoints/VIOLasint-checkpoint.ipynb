{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e004327d-2424-4766-a61c-dfd4bfee6107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, least_squares\n",
    "import csv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce5a01c-95df-4e51-a33e-131a6009ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LidarEnhancedVO:\n",
    "    def __init__(self, image_folder, lidar_ref_path, known_altitude, K, dt=2.0):\n",
    "        self.K = K\n",
    "        self.known_altitude = known_altitude\n",
    "        \n",
    "        # Initialize ORB with your parameters\n",
    "        self.orb = cv2.ORB_create(nfeatures=5000, scaleFactor=1.2, nlevels=8)\n",
    "        \n",
    "        # FLANN matcher parameters from your implementation\n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "        search_params = dict(checks=50)\n",
    "        self.flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        \n",
    "        # Load and process LiDAR reference\n",
    "        self.lidar_ref = cv2.imread(lidar_ref_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if self.lidar_ref is None:\n",
    "            raise ValueError(f\"Could not load LiDAR reference: {lidar_ref_path}\")\n",
    "        self.lidar_ref = self.enhance_contrast(self.lidar_ref)\n",
    "        self.lidar_kp, self.lidar_desc = self.orb.detectAndCompute(self.lidar_ref, None)\n",
    "        \n",
    "        # Initialize Kalman Filter states\n",
    "        self.init_kalman(dt)\n",
    "        \n",
    "        # Load and preprocess images\n",
    "        self.load_images(image_folder)\n",
    "        \n",
    "        # Initialize trajectory storage\n",
    "        self.trajectory = [np.zeros(3)]\n",
    "        self.all_descriptors = [self.descriptors[0]]\n",
    "        # Initialize pose tracking\n",
    "        self.R_total = np.eye(3)\n",
    "        self.t_total = np.zeros((3, 1))\n",
    "        \n",
    "    def detect_loop_closures(self, distance_threshold=5.0, similarity_threshold=0.6):\n",
    "        \"\"\"Detect loop closures in the trajectory\"\"\"\n",
    "        loop_closures = []\n",
    "        trajectory_array = np.array(self.trajectory)\n",
    "        \n",
    "        nn = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "        nn.fit(trajectory_array)\n",
    "        \n",
    "        for i in range(len(trajectory_array)):\n",
    "            distances, indices = nn.kneighbors([trajectory_array[i]])\n",
    "            for j, distance in zip(indices[0], distances[0]):\n",
    "                if j > i + 10 and distance < distance_threshold:  # Avoid consecutive frames\n",
    "                    # Check descriptor similarity\n",
    "                    matches = self.flann.knnMatch(self.all_descriptors[i], \n",
    "                                                self.all_descriptors[j], k=2)\n",
    "                    good_matches = []\n",
    "                    for match in matches:\n",
    "                        if len(match) == 2:\n",
    "                            m, n = match\n",
    "                            if m.distance < 0.68 * n.distance:\n",
    "                                good_matches.append(m)\n",
    "                    \n",
    "                    if len(good_matches) / len(matches) > similarity_threshold:\n",
    "                        loop_closures.append((i, j))\n",
    "        \n",
    "        return loop_closures\n",
    "        \n",
    "    def init_kalman(self, dt):\n",
    "        self.x_kalman = np.zeros(9)  # [x, y, z, vx, vy, vz, roll, pitch, yaw]\n",
    "        self.P_kalman = np.eye(9)\n",
    "        self.Q_kalman = np.eye(9) * 1e-5\n",
    "        self.R_kalman = np.eye(3) * 0.01\n",
    "        \n",
    "        self.F_kalman = np.eye(9)\n",
    "        self.F_kalman[0, 3] = self.F_kalman[1, 4] = self.F_kalman[2, 5] = dt\n",
    "        \n",
    "        self.H_kalman = np.zeros((3, 9))\n",
    "        self.H_kalman[0, 0] = self.H_kalman[1, 1] = self.H_kalman[2, 2] = 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def enhance_contrast(image):\n",
    "        clahe = cv2.createCLAHE(clipLimit=5, tileGridSize=(8,8))\n",
    "        return clahe.apply(image)\n",
    "\n",
    "    def create_pose_graph(self, loop_closures):\n",
    "        \"\"\"Create pose graph with loop closure constraints\"\"\"\n",
    "        g = nx.Graph()\n",
    "        \n",
    "        # Add sequential edges\n",
    "        for i in range(len(self.trajectory) - 1):\n",
    "            g.add_edge(i, i+1, weight=1.0)\n",
    "        \n",
    "        # Add loop closure edges\n",
    "        for i, j in loop_closures:\n",
    "            g.add_edge(i, j, weight=0.1)  # Lower weight for loop closures\n",
    "        \n",
    "        return g\n",
    "\n",
    "    def optimize_pose_graph(self, trajectory):\n",
    "        \"\"\"Optimize the pose graph\"\"\"\n",
    "        n = len(trajectory)\n",
    "        \n",
    "        def objective(x):\n",
    "            residuals = []\n",
    "            poses = x.reshape(-1, 3)\n",
    "            \n",
    "            # Sequential constraints\n",
    "            for i in range(len(poses) - 1):\n",
    "                residuals.append((poses[i+1] - poses[i]) * 1.0)  # Weight for sequential\n",
    "            \n",
    "            # Loop closure constraints\n",
    "            for i, j in self.loop_closures:\n",
    "                residuals.append((poses[j] - poses[i]) * 0.1)  # Weight for loop closures\n",
    "            \n",
    "            return np.concatenate(residuals)\n",
    "        \n",
    "        # Optimize\n",
    "        x0 = trajectory.flatten()\n",
    "        res = least_squares(objective, x0)\n",
    "        return res.x.reshape(-1, 3)\n",
    "    \n",
    "    def load_images(self, image_folder):\n",
    "        image_files = sorted([f for f in os.listdir(image_folder) \n",
    "                            if f.endswith(('.jpg', '.png'))])\n",
    "        \n",
    "        self.images = []\n",
    "        self.gray_images = []\n",
    "        self.keypoints = []\n",
    "        self.descriptors = []\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            img_path = os.path.join(image_folder, image_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            gray_img = self.enhance_contrast(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "            \n",
    "            self.images.append(img)\n",
    "            self.gray_images.append(gray_img)\n",
    "            \n",
    "            kp, desc = self.orb.detectAndCompute(gray_img, None)\n",
    "            self.keypoints.append(kp)\n",
    "            self.descriptors.append(desc)\n",
    "    \n",
    "    def match_with_lidar(self, frame_desc):\n",
    "        \"\"\"Match current frame with LiDAR reference\"\"\"\n",
    "        matches = self.flann.knnMatch(frame_desc, self.lidar_desc, k=2)\n",
    "        good_matches = []\n",
    "        for match in matches:\n",
    "            if len(match) == 2:\n",
    "                m, n = match\n",
    "                if m.distance < 0.6 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "        return good_matches\n",
    "    \n",
    "    def estimate_pose(self, p1, p2):\n",
    "        \"\"\"Estimate relative pose with Essential matrix refinement\"\"\"\n",
    "        E, mask = cv2.findEssentialMat(p1, p2, self.K, method=cv2.RANSAC, \n",
    "                                     prob=0.999, threshold=0.5)\n",
    "        E_refined = self.refine_E(E, p1, p2)\n",
    "        _, R, t, mask = cv2.recoverPose(E_refined, p1, p2, self.K)\n",
    "        return R, t, mask\n",
    "    \n",
    "    def refine_E(self, E, p1, p2):\n",
    "        \"\"\"Refine Essential matrix using your existing method\"\"\"\n",
    "        def objective(E_vec):\n",
    "            E_mat = E_vec.reshape(3, 3)\n",
    "            p1_norm = cv2.undistortPoints(p1.reshape(-1, 1, 2), self.K, None).reshape(-1, 2)\n",
    "            p2_norm = cv2.undistortPoints(p2.reshape(-1, 1, 2), self.K, None).reshape(-1, 2)\n",
    "            error = 0\n",
    "            for i in range(len(p1_norm)):\n",
    "                p1_homogeneous = np.append(p1_norm[i], 1)\n",
    "                p2_homogeneous = np.append(p2_norm[i], 1)\n",
    "                error += np.abs(np.dot(p2_homogeneous, np.dot(E_mat, p1_homogeneous)))\n",
    "            return error\n",
    "        \n",
    "        result = minimize(objective, E.flatten(), method='Nelder-Mead')\n",
    "        return result.x.reshape(3, 3)\n",
    "    \n",
    "    def process_frame(self, i, last_keyframe_index):\n",
    "        \"\"\"Process a single frame with both consecutive and LiDAR matching\"\"\"\n",
    "        if not self.is_keyframe(self.keypoints[i], self.keypoints[last_keyframe_index]):\n",
    "            return None, last_keyframe_index\n",
    "            \n",
    "        # Match with previous keyframe\n",
    "        matches = self.flann.knnMatch(self.descriptors[last_keyframe_index], \n",
    "                                    self.descriptors[i], k=2)\n",
    "        good_matches = []\n",
    "        for match in matches:\n",
    "            if len(match) == 2:\n",
    "                m, n = match\n",
    "                if m.distance < 0.6 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "                    \n",
    "        if len(good_matches) > 10:\n",
    "            # Get matching points\n",
    "            p1 = np.float32([self.keypoints[last_keyframe_index][m.queryIdx].pt \n",
    "                            for m in good_matches])\n",
    "            p2 = np.float32([self.keypoints[i][m.trainIdx].pt \n",
    "                            for m in good_matches])\n",
    "            \n",
    "            # Estimate pose from consecutive frames\n",
    "            R_cons, t_cons, mask = self.estimate_pose(p1, p2)\n",
    "            \n",
    "            # Match with LiDAR reference\n",
    "            lidar_matches = self.match_with_lidar(self.descriptors[i])\n",
    "            \n",
    "            if len(lidar_matches) > 10:\n",
    "                # Get matching points for LiDAR\n",
    "                p_frame = np.float32([self.keypoints[i][m.queryIdx].pt \n",
    "                                    for m in lidar_matches])\n",
    "                p_lidar = np.float32([self.lidar_kp[m.trainIdx].pt \n",
    "                                    for m in lidar_matches])\n",
    "                \n",
    "                # Estimate pose relative to LiDAR\n",
    "                R_lidar, t_lidar, _ = self.estimate_pose(p_frame, p_lidar)\n",
    "                \n",
    "                # Combine estimates (weighted average based on match confidence)\n",
    "                w_cons = len(good_matches) / (len(good_matches) + len(lidar_matches))\n",
    "                w_lidar = len(lidar_matches) / (len(good_matches) + len(lidar_matches))\n",
    "                \n",
    "                R = (w_cons * R_cons + w_lidar * R_lidar)\n",
    "                t = (w_cons * t_cons + w_lidar * t_lidar)\n",
    "            else:\n",
    "                R, t = R_cons, t_cons\n",
    "            \n",
    "            # Apply Kalman filter\n",
    "            z_kalman = t.flatten()\n",
    "            x_pred = self.F_kalman @ self.x_kalman\n",
    "            P_pred = self.F_kalman @ self.P_kalman @ self.F_kalman.T + self.Q_kalman\n",
    "            \n",
    "            y_kalman = z_kalman - self.H_kalman @ x_pred\n",
    "            S_kalman = self.H_kalman @ P_pred @ self.H_kalman.T + self.R_kalman\n",
    "            K_kalman = P_pred @ self.H_kalman.T @ np.linalg.inv(S_kalman)\n",
    "            \n",
    "            self.x_kalman = x_pred + K_kalman @ y_kalman\n",
    "            self.P_kalman = (np.eye(len(self.P_kalman)) - K_kalman @ self.H_kalman) @ P_pred\n",
    "            \n",
    "            return (R, t, self.x_kalman[:3]), i\n",
    "        \n",
    "        return None, last_keyframe_index\n",
    "    \n",
    "    def optimize_trajectory(self):\n",
    "        \"\"\"Optimize trajectory using loop closure detection\"\"\"\n",
    "        self.loop_closures = self.detect_loop_closures()\n",
    "        if self.loop_closures:\n",
    "            print(f\"Loop closures detected: {self.loop_closures}\")\n",
    "            pose_graph = self.create_pose_graph(self.loop_closures)\n",
    "            optimized_trajectory = self.optimize_pose_graph(np.array(self.trajectory))\n",
    "            scaled_trajectory = self.scale_trajectory_constant_altitude(optimized_trajectory)\n",
    "            self.trajectory = list(scaled_trajectory)\n",
    "            \n",
    "            # Update total transformation\n",
    "            if len(self.trajectory) > 1:\n",
    "                direction = self.trajectory[-1] - self.trajectory[-2]\n",
    "                R_update, _ = cv2.Rodrigues(direction)\n",
    "                self.R_total = R_update @ self.R_total\n",
    "                self.t_total = self.trajectory[-1].reshape(3, 1)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run the complete VO pipeline\"\"\"\n",
    "        last_keyframe_index = 0\n",
    "        \n",
    "        for i in range(1, len(self.images)):\n",
    "            result, last_keyframe_index = self.process_frame(i, last_keyframe_index)\n",
    "            \n",
    "            if result is not None:\n",
    "                R, t, refined_position = result\n",
    "                self.R_total = R @ self.R_total\n",
    "                self.t_total = R @ self.t_total + t\n",
    "                \n",
    "                self.trajectory.append(refined_position)\n",
    "                self.all_descriptors.append(self.descriptors[i])\n",
    "                \n",
    "                # Perform loop closure and optimization periodically\n",
    "                if len(self.trajectory) % 20 == 0:\n",
    "                    self.optimize_trajectory()\n",
    "        \n",
    "        # Final scaling\n",
    "        final_trajectory = np.array(self.trajectory)\n",
    "        return self.scale_trajectory_constant_altitude(final_trajectory)\n",
    "\n",
    "    def scale_trajectory_constant_altitude(self, trajectory):\n",
    "\n",
    "        avg_z = np.mean(trajectory[:, 2])\n",
    "        scale_factor = self.known_altitude / avg_z if avg_z != 0 else 1\n",
    "        scaled_trajectory = trajectory * scale_factor\n",
    "        scaled_trajectory[:, 2] = self.known_altitude\n",
    "        return scaled_trajectory\n",
    "\n",
    "    def visualize_trajectory_on_lidar(self, save_path=None):\n",
    "        lidar_viz = cv2.cvtColor(self.lidar_ref, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Get trajectory points\n",
    "        trajectory = np.array(self.trajectory)\n",
    "        \n",
    "        # Find trajectory bounds\n",
    "        min_x, max_x = trajectory[:, 0].min(), trajectory[:, 0].max()\n",
    "        min_y, max_y = trajectory[:, 1].min(), trajectory[:, 1].max()\n",
    "        \n",
    "        # Get image dimensions\n",
    "        img_height, img_width = self.lidar_ref.shape[:2]\n",
    "        \n",
    "        # Transform trajectory points to image coordinates\n",
    "        trajectory_img = []\n",
    "        for point in trajectory:\n",
    "            # Normalize coordinates to image space\n",
    "            x_img = int(((point[0] - min_x) / (max_x - min_x)) * (img_width - 20) + 10)\n",
    "            y_img = int(((point[1] - min_y) / (max_y - min_y)) * (img_height - 20) + 10)\n",
    "            trajectory_img.append([x_img, y_img])\n",
    "        \n",
    "        trajectory_img = np.array(trajectory_img)\n",
    "        \n",
    "        # Draw trajectory\n",
    "        # Draw lines between points\n",
    "        for i in range(len(trajectory_img) - 1):\n",
    "            pt1 = tuple(trajectory_img[i])\n",
    "            pt2 = tuple(trajectory_img[i + 1])\n",
    "            cv2.line(lidar_viz, pt1, pt2, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw points\n",
    "        for i, point in enumerate(trajectory_img):\n",
    "            # Start point in red\n",
    "            if i == 0:\n",
    "                cv2.circle(lidar_viz, tuple(point), 5, (0, 0, 255), -1)\n",
    "            # End point in blue\n",
    "            elif i == len(trajectory_img) - 1:\n",
    "                cv2.circle(lidar_viz, tuple(point), 5, (255, 0, 0), -1)\n",
    "            # Intermediate points in green\n",
    "            else:\n",
    "                cv2.circle(lidar_viz, tuple(point), 3, (0, 255, 0), -1)\n",
    "        \n",
    "        # Add legend\n",
    "        legend_height = 60\n",
    "        legend = np.ones((legend_height, img_width, 3), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Draw legend items\n",
    "        cv2.circle(legend, (30, 30), 5, (0, 0, 255), -1)\n",
    "        cv2.putText(legend, \"Start\", (50, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "        \n",
    "        cv2.circle(legend, (130, 30), 5, (255, 0, 0), -1)\n",
    "        cv2.putText(legend, \"End\", (150, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "        \n",
    "        cv2.circle(legend, (230, 30), 3, (0, 255, 0), -1)\n",
    "        cv2.line(legend, (260, 30), (290, 30), (0, 255, 0), 2)\n",
    "        cv2.putText(legend, \"Trajectory\", (300, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "        \n",
    "        # Combine visualization and legend\n",
    "        final_viz = np.vstack((lidar_viz, legend))\n",
    "        \n",
    "        # Display\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(final_viz, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title('Trajectory Overlay on LiDAR Intensity Map')\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "            print(f\"Visualization saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def is_keyframe(current_kp, last_keyframe_kp, min_matches=50):\n",
    "        if len(last_keyframe_kp) == 0:\n",
    "            return True\n",
    "        return len(current_kp) >= min_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e137d21-8051-41e0-893d-ac10a32c9b78",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Camera matrix from your implementation\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     K \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[0;32m      5\u001b[0m         [\u001b[38;5;241m4085.11\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3000\u001b[39m],\n\u001b[0;32m      6\u001b[0m         [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4102.56\u001b[39m, \u001b[38;5;241m2000\u001b[39m],\n\u001b[0;32m      7\u001b[0m         [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m     ])\n\u001b[0;32m     10\u001b[0m     vo \u001b[38;5;241m=\u001b[39m LidarEnhancedVO(\n\u001b[1;32m---> 11\u001b[0m         image_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPath to images : \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     12\u001b[0m         lidar_ref_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath to lidar intensity image : \u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     13\u001b[0m         known_altitude\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100.0\u001b[39m,\n\u001b[0;32m     14\u001b[0m         K\u001b[38;5;241m=\u001b[39mK\n\u001b[0;32m     15\u001b[0m     )\n\u001b[0;32m     17\u001b[0m     final_trajectory \u001b[38;5;241m=\u001b[39m vo\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m     18\u001b[0m     vo\u001b[38;5;241m.\u001b[39mvisualize_trajectory_on_lidar(save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrajectory_overlay.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Optional save_path\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Camera matrix from your implementation\n",
    "    K = np.array([\n",
    "        [4085.11, 0, 3000],\n",
    "        [0, 4102.56, 2000],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    vo = LidarEnhancedVO(\n",
    "        image_folder=input(\"Path to images : \"),\n",
    "        lidar_ref_path=input(\"Path to lidar intensity image : \"),\n",
    "        known_altitude=50.0,\n",
    "        K=K\n",
    "    )\n",
    "    \n",
    "    final_trajectory = vo.run()\n",
    "    vo.visualize_trajectory_on_lidar(save_path=\"trajectory_overlay.png\")  # Optional save_path\n",
    "    # Visualization\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot(final_trajectory[:, 0], final_trajectory[:, 1], final_trajectory[:, 2], marker='o')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Enhanced Camera Trajectory with LiDAR Reference')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save results\n",
    "    np.savetxt('enhanced_trajectory.csv', final_trajectory, delimiter=',', \n",
    "               header='X,Y,Z', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb520a-6ef6-4c69-91be-f44f376df74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
